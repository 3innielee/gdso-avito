{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07/31 train-rmse:0.242975;\t valid-rmse:0.249397"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **V** Number of characters in title\n",
    "- **V** Number of characters in description\n",
    "- **V** tfidf of description\n",
    "- **V** tfidf of title\n",
    "\n",
    "- Number of words\n",
    "- Average Word Length\n",
    "- Number of stopwords\n",
    "- Number of special characters\n",
    "\n",
    "- if the description is empty (replace with 'NA' string is fine. and then create another boolean feature)\n",
    "- try new features to see if the result improved\n",
    "- search for keywords in description of title. i.e. \"new\" or \"old\"\n",
    "- empty description will be 0 after tfidf?\n",
    "- check the predicted value, see if they fall into [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('precision', 5)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train = pd.read_csv('data/train.csv')\n",
    "#test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"item_id\"].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[[\"item_id\",\"title\",\"description\",\"deal_probability\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "train['char_len_title'] = train.title.apply(lambda x: len(str(x)))\n",
    "train['char_len_desc'] = train.description.apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>deal_probability</th>\n",
       "      <th>char_len_title</th>\n",
       "      <th>char_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>0.12789</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>17</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>В хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>0.43177</td>\n",
       "      <td>14</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>Продам кресло от0-25кг</td>\n",
       "      <td>0.80323</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>Все вопросы по телефону.</td>\n",
       "      <td>0.20797</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                  title  \\\n",
       "0  b912c3c6a6ad  Кокоби(кокон для сна)   \n",
       "1  2dac0150717d      Стойка для Одежды   \n",
       "2  ba83aefab5dc         Philips bluray   \n",
       "3  02996f1dd2ea             Автокресло   \n",
       "4  7c90be56d2ab         ВАЗ 2110, 2003   \n",
       "\n",
       "                                         description  deal_probability  \\\n",
       "0  Кокон для сна малыша,пользовались меньше месяц...           0.12789   \n",
       "1          Стойка для одежды, под вешалки. С бутика.           0.00000   \n",
       "2  В хорошем состоянии, домашний кинотеатр с blu ...           0.43177   \n",
       "3                             Продам кресло от0-25кг           0.80323   \n",
       "4                           Все вопросы по телефону.           0.20797   \n",
       "\n",
       "   char_len_title  char_len_desc  \n",
       "0              21             58  \n",
       "1              17             41  \n",
       "2              14             99  \n",
       "3              10             22  \n",
       "4              14             24  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to change data type from object to unicode\n",
    "train[\"description\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphological analyzer for Russian language 14:25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "retoken = re.compile(r'[\\'\\w\\-]+')\n",
    "def normalize(text):\n",
    "    text = retoken.findall(text.lower()) # make all text lowercase\n",
    "    text = [morph.parse(x)[0].normal_form for x in text] # morphological analysis\n",
    "    return ' '.join(text)\n",
    "\n",
    "train['title'] = train['title'].astype(str)\n",
    "train['description'] = train['description'].astype(str)\n",
    "\n",
    "train['title'] = train['title'].apply(normalize)\n",
    "train['description'] = train['description'].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# tfidf for description\n",
    "train['description']=train['description'].fillna('NA')\n",
    "tfidf = TfidfVectorizer(max_features=100, stop_words = stopWords)\n",
    "tfidf_train = np.array(tfidf.fit_transform(train['description'].values.astype('U')).todense(), dtype=np.float16)\n",
    "for i in range(100):\n",
    "    train['tfidf_des_' + str(i)] = tfidf_train[:, i]\n",
    "\n",
    "# tfidf for title\n",
    "train['title']=train['title'].fillna('NA')\n",
    "tfidf_title_train = np.array(tfidf.fit_transform(train['title'].values.astype('U')).todense(), dtype=np.float16)\n",
    "for i in range(100):\n",
    "    train['tfidf_title_' + str(i)] = tfidf_title_train[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = train['deal_probability']\n",
    "X = train.drop(['deal_probability','item_id','title','description'],axis=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=99)\n",
    "##X_val = X_val.drop(['deal_probability'],axis=1)\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# grid search result\n",
    "params = {'eta': 0.3,\n",
    "          'tree_method': \"hist\",\n",
    "          'grow_policy': \"lossguide\",\n",
    "          'max_leaves': 1400,  \n",
    "          'max_depth': 0, \n",
    "          'subsample': 0.9, \n",
    "          'colsample_bytree': 0.7, \n",
    "          'colsample_bylevel':0.7,\n",
    "          'min_child_weight':0,\n",
    "          'alpha':4,\n",
    "          'objective': 'reg:logistic', \n",
    "          'eval_metric': 'rmse', \n",
    "          'random_state': 99, \n",
    "          'silent': True}\n",
    "\n",
    "tr_data = xgb.DMatrix(X_train, y_train)\n",
    "va_data = xgb.DMatrix(X_val, y_val)\n",
    "del X_train\n",
    "del X_val\n",
    "del y_train\n",
    "del y_val\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "watchlist = [(tr_data, 'train'), (va_data, 'valid')]\n",
    "\n",
    "model = xgb.train(params, tr_data, 1000, watchlist, maximize=False, early_stopping_rounds = 25, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate result for test dataset\n",
    "\n",
    "#X_te = xgb.DMatrix(X_te)\n",
    "#y_pred = model.predict(X_te, ntree_limit=model.best_ntree_limit)\n",
    "#sub = pd.read_csv('../input/sample_submission.csv')\n",
    "#sub['deal_probability'] = y_pred\n",
    "#sub['deal_probability'].clip(0.0, 1.0, inplace=True)\n",
    "#sub.to_csv('xgb_with_mean_encode_and_nlp.csv', index=False)\n",
    "#sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting \n",
    "\n",
    "#from xgboost import plot_importance\n",
    "#import matplotlib.pyplot as plt\n",
    "#plot_importance(model)\n",
    "#plt.gcf().savefig('feature_importance_xgb.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
